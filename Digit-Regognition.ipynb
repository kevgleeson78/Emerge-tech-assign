{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital recognition with the mnist dataset\n",
    "\n",
    "This notebook will investigate the classification and identification of hand written digits using a neural network.<br/>\n",
    "The mnist dataset will be first used to train the network and then test the networks performance in recognising a digit.<br/>\n",
    "Once training has been completed twenty random test images from the dataset will be passed to the network and the result will be displayed to the screen along with the actual digit expected.<br/>\n",
    "![Mnist Image](https://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png)\n",
    "<cite>Image source https://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png</cite>\n",
    "\n",
    "## Saving the model\n",
    "For convienience the training model has been saved to a file. This can be loaded from the user input prompt or overwritten if you want to rerun the training.<br/>\n",
    "\n",
    "I have the saved model file in the main folder of the repository. For it to work you will need to move this file into the data folder you have created for the gzip files.<br/>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages needed for the program to run\n",
    "\n",
    "The following packages will need to be imported for creating the network and importing the images to memory:\n",
    "* The keras package used for creating the network\n",
    "* The gzip package used for unzipping the dataset images and labels\n",
    "* The numpy package used for altering the dataset into numpy arrays\n",
    "* The sklearn pre-processing package used for classification and binary encoding each digit\n",
    "* The random package used to generate a random value for the test images\n",
    "* tkinter for uploading you own image files\n",
    "* pathlib for checking the existence of the saved model file\n",
    "* numpy random package for selecting random images from the test set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import keras for building the nural network\n",
    "import keras as kr\n",
    "\n",
    "# Import gzip for unpacking the images and labels\n",
    "import gzip\n",
    "\n",
    "# Import numpy\n",
    "import numpy as np\n",
    "\n",
    "# Import sklearn for categorising each digit\n",
    "import sklearn.preprocessing as pre\n",
    "\n",
    "# inport imge for resizing\n",
    "from keras.preprocessing import image\n",
    "\n",
    "# tkinter for selecting images\n",
    "import tkinter as tk\n",
    "# For opening file upload dialog\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Used for checking if the model file exists.\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the neural network\n",
    "To begin we need to initialise the network using the sequential model.<br/>\n",
    "This allows us to add layers as we need them. <br/>\n",
    "These layers can be tweaked to increase performance.<br/>\n",
    "We will investigate this later in the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code in this script was mainly Adapted from: https://raw.githubusercontent.com/ianmcloughlin/jupyter-teaching-notebooks/master/mnist.ipynb\n",
    "# Initialise the neural network\n",
    "model = kr.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the layers to the network\n",
    "To add layers to the network the layers method from keras will be used.<br/>\n",
    "There will be a dense connection between neurons meaning that every neuron from the input is connected to every neuron in the middle layer and every neuron frim the middle layer is connected to every neuron on the output layer.\n",
    "\n",
    "![Neural Network](https://cdn-images-1.medium.com/max/800/1*jYhgQ4I_oFdxgDD-AOgV1w.png)\n",
    "<cite>Image source https://cdn-images-1.medium.com/max/800/1*jYhgQ4I_oFdxgDD-AOgV1w.pngS</cite>\n",
    "\n",
    "* In the below code segment the units attribute represents the amount of neurons that will be in the middle layer in this case we have 1000 neurons.<br/>\n",
    "* The activation attribute sets the activation function in this case we are using  [relu activation](https://keras.io/activations/) the relu activation has a steeper gradient than softmax and as a result speeds up the training process without the loss of performance. \n",
    "\n",
    "* The final attribute is used to set the amount of input neurons the network has. In the below example the number is set to 784 as this is equal to the number of bytes each image has within the mnist dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a hidden(middle layer) with 1000 neurons and an input layer with 784.\n",
    "# There are 784 input neurons as this value is equal to the total amount of bytes each image has.\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu', input_dim=784))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layer\n",
    "The output layer has ten neurons that will map to the amount of training labels that are within the dataset. The predicted results are sent from the middle layer to the output layer and compared to the actual number that has been sent in as image data.<br/>\n",
    "The closer to the value one the result is the more accurate the algorithm is performing.<br/>\n",
    "While this process is repeating the loss point of gradient decent converges towards the base of the slope. <br/>\n",
    "The process ends when all of the epochs have completed which will be explained later in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ten neurons to the output layer\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "The compile method is used to build the model based on each layer created along with their connections specified in the above cell.</br>\n",
    "* The first argument [categorical_crossentropy](https://keras.io/losses/) creates a vector to hold the values of each digit as a binary representation, this will be set with the pre.LabelBinarizer() to be discussed further in this notebook.\n",
    "* The second optimizer argument is set to [stochastic gradient descent optimizer](https://keras.io/optimizers/) This sets the learning rate, and the decay of this learning rate over time.\n",
    "* The final argument [metrics](https://keras.io/metrics/) is used to output the performance to the neural network after each run of data has been sent from the central layer to the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the files in .gz format\n",
    "\n",
    "As discussed in my previous [mnist notebook](https://github.com/kevgleeson78/Emerge-tech-assign/blob/master/Mnist%20Dataset.ipynb) the gzipped files are opened and read using the gzip package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the gzipped files and read as bytes.\n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data into memory\n",
    "\n",
    "Each of the 60000 images and labels are then stored into their respective variables.<br/>\n",
    "We dived by 255 to convert the grey scale value to a value between one and zero.<br/>\n",
    "These values are then used by the neural network in conjunction with the softmax function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all images and labels into memory\n",
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0\n",
    "train_lbl =  np.array(list(train_lbl[8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening the data into a single array\n",
    "The data is converted from a three dimensional array to a one dimensional array where all of the image bytes (28 *28) 784 are sequentially stored one after another.<br/>\n",
    "This technique is used so each byte representing the image can have a one to one mapping to the neural networks input layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.98823529, 0.92941176, 0.92941176,\n",
       "        0.92941176, 0.50588235, 0.46666667, 0.31372549, 0.89803922,\n",
       "        0.34901961, 0.        , 0.03137255, 0.50196078, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.88235294, 0.85882353, 0.63137255, 0.39607843,\n",
       "        0.33333333, 0.00784314, 0.00784314, 0.00784314, 0.00784314,\n",
       "        0.00784314, 0.11764706, 0.3254902 , 0.00784314, 0.05098039,\n",
       "        0.23529412, 0.74901961, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.80784314, 0.06666667,\n",
       "        0.00784314, 0.00784314, 0.00784314, 0.00784314, 0.00784314,\n",
       "        0.00784314, 0.00784314, 0.00784314, 0.01568627, 0.63529412,\n",
       "        0.67843137, 0.67843137, 0.78039216, 0.84705882, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.92941176, 0.14117647, 0.00784314, 0.00784314,\n",
       "        0.00784314, 0.00784314, 0.00784314, 0.22352941, 0.28627451,\n",
       "        0.03137255, 0.05490196, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.68627451, 0.38823529, 0.58039216, 0.00784314, 0.00784314,\n",
       "        0.19607843, 0.95686275, 1.        , 0.83137255, 0.39607843,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.94509804,\n",
       "        0.99607843, 0.39607843, 0.00784314, 0.64705882, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.45490196,\n",
       "        0.00784314, 0.25490196, 0.99215686, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.95686275, 0.25490196, 0.00784314,\n",
       "        0.7254902 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.8627451 , 0.05490196, 0.11764706, 0.37254902,\n",
       "        0.57647059, 0.99607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.68235294, 0.05882353, 0.00784314, 0.00784314, 0.53333333,\n",
       "        0.90196078, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.82352941,\n",
       "        0.27058824, 0.00784314, 0.00784314, 0.41176471, 0.89411765,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.9372549 , 0.63529412,\n",
       "        0.01176471, 0.00784314, 0.26666667, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.02352941, 0.00784314,\n",
       "        0.02352941, 0.74901961, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.81960784, 0.49019608,\n",
       "        0.28235294, 0.00784314, 0.00784314, 0.18823529, 0.99215686,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.84705882,\n",
       "        0.41960784, 0.10196078, 0.00784314, 0.00784314, 0.00784314,\n",
       "        0.01960784, 0.28627451, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.90588235, 0.55294118, 0.13333333, 0.00784314, 0.00784314,\n",
       "        0.00784314, 0.00784314, 0.21176471, 0.69411765, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.90980392, 0.74117647, 0.16470588, 0.00784314,\n",
       "        0.00784314, 0.00784314, 0.00784314, 0.22352941, 0.68235294,\n",
       "        0.99215686, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.92941176, 0.32941176, 0.14117647,\n",
       "        0.00784314, 0.00784314, 0.00784314, 0.00784314, 0.23529412,\n",
       "        0.68627451, 0.96470588, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.78431373, 0.3254902 ,\n",
       "        0.11372549, 0.00784314, 0.00784314, 0.00784314, 0.00784314,\n",
       "        0.04313725, 0.47843137, 0.95686275, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.46666667, 0.00784314, 0.00784314, 0.00784314,\n",
       "        0.16862745, 0.47058824, 0.48235294, 0.9372549 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the array so the inputs can be mapped to the input neurons\n",
    "inputs = train_img.reshape(60000, 784)\n",
    "inputs[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the data\n",
    "The label data is encoded into a matrix of 10 x 10 this will represent the digits in binary format.\n",
    "Firstly we to setup the matrix using the labelBinerizer function.<br/>\n",
    "The fit function passes the training labels as an argument. AS the set of labels are from zero - nine the (encoder.fit) function generates a matrix based on these values. In this case it will be a 10 x 10 matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode the labels into binary format\n",
    "encoder = pre.LabelBinarizer()\n",
    "# get the size of the array needed for each category\n",
    "encoder.fit(train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the labels\n",
    "The labels are then transformed to a binary value based on the decimal value of the label.</br>\n",
    "With each number being transformed to the following:\n",
    "* (0) 1000000000\n",
    "* (1) 0100000000\n",
    "* (3) 0010000000 \n",
    "\n",
    "And so on until we reach the number nine which is 0000000001.<br/>\n",
    "\n",
    "\n",
    "In the below example the number five has the representation of '0 0 0 0 0 1 0 0 0 0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# encode each label to be used as binary outputs\n",
    "outputs = encoder.transform(train_lbl)\n",
    "# print out the integer value and the new representation of the number\n",
    "print(train_lbl[0], outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full example\n",
    "Below is a full view of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[1 0 0 0 0 0 0 0 0 0]]\n",
      "1 [[0 1 0 0 0 0 0 0 0 0]]\n",
      "2 [[0 0 1 0 0 0 0 0 0 0]]\n",
      "3 [[0 0 0 1 0 0 0 0 0 0]]\n",
      "4 [[0 0 0 0 1 0 0 0 0 0]]\n",
      "5 [[0 0 0 0 0 1 0 0 0 0]]\n",
      "6 [[0 0 0 0 0 0 1 0 0 0]]\n",
      "7 [[0 0 0 0 0 0 0 1 0 0]]\n",
      "8 [[0 0 0 0 0 0 0 0 1 0]]\n",
      "9 [[0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# print out each array\n",
    "for i in range(10):\n",
    "    print(i, encoder.transform([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "We are now ready to begin training the network to recognise the images.</br>\n",
    "The training set of 60000 images are used and passed to the networks first layer of 784 neurons.<br/>\n",
    "Model parameters:\n",
    "1. The encoded training images are sent as input\n",
    "2. The encoded training labels are attached as the expected output\n",
    "3. Epochs is the amount of times the 60000 images will be processed \n",
    "4. The batch size sets the amount of images that will be sent to the network as one unit\n",
    "\n",
    "## train_model function\n",
    "Used for an option to start traing. If function is run the final model will be saved to a file in the data folder. This file can then be loaded for future use rather than training the model every time we run the program. THe user qill be prompted to choose if they wish to load the model or start training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train model function for user input\n",
    "def train_model():\n",
    "    # Start the training\n",
    "    # Set the model up by adding the input and output layers to the network\n",
    "    #The epochs value is the amount of test runs are needed\n",
    "    # The batch_size value is the amount of images sent at one time to the network\n",
    "    model.fit(inputs, outputs, epochs=50, batch_size=100)\n",
    "    # adapted from https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model\n",
    "    # save the model to a file for future use\n",
    "    model.save(\"data/my_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of the training\n",
    "\n",
    "After 50 epochs the network is getting approx 96.5% of the images correct for the training set.<br/>\n",
    "With each epoch the performance is slightly increasing and the loss is converging towards zero (The optimal value).\n",
    "## Saving the model\n",
    "We can now save the above training model weights to a file for future access. This file will be saved to the same data folder you have created for the gzip files.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load_model function\n",
    "This function will be called if the user chooses from the input prompt.<br/>\n",
    "If called the model file will be loaded and we can begin testing straight away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading the model weights file\n",
    "def load_model():\n",
    "    model.load_weights(\"data/my_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User input for loading model or run training\n",
    "The below input prompt asks the user to choose loading the model file or run training the model. <br/>\n",
    "If the user chooses 'y' a further condition is used to check if the file exists.<br/>\n",
    "If The file exits the load_model() function is called. <br/>\n",
    "If the files does not exist the trian_model() function is called and training begins.<br/>\n",
    "Once training has completed the saved model file will be created for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please choose an option and press enter: \n",
      "Load model = y/ train model = n \n",
      "y\n",
      "No file exists running training.....\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 16s 259us/step - loss: 0.8909 - acc: 0.77910s - loss: 0.912\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 0.4637 - acc: 0.87540s - loss: 0.4658 \n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 0.3955 - acc: 0.8896\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 15s 255us/step - loss: 0.3629 - acc: 0.8978\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.3423 - acc: 0.9019\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.3272 - acc: 0.9069\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.3154 - acc: 0.9091\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.3054 - acc: 0.9121\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.2969 - acc: 0.9146\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.2884 - acc: 0.9170\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.2804 - acc: 0.9193\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.2735 - acc: 0.9222\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.2658 - acc: 0.9244\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 0.2598 - acc: 0.9264\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 17s 277us/step - loss: 0.2534 - acc: 0.9280\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 0.2465 - acc: 0.9313\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.2407 - acc: 0.9322\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 15s 244us/step - loss: 0.2346 - acc: 0.9343\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.2281 - acc: 0.9361\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 17s 284us/step - loss: 0.2231 - acc: 0.9373\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 15s 258us/step - loss: 0.2176 - acc: 0.9389\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 18s 294us/step - loss: 0.2122 - acc: 0.9407\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.2076 - acc: 0.9423\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 18s 307us/step - loss: 0.2029 - acc: 0.94340s - loss: 0.2028 - acc: 0.94\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 18s 298us/step - loss: 0.1982 - acc: 0.9449\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.1933 - acc: 0.9457\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.1893 - acc: 0.9473\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.1854 - acc: 0.9481\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 15s 256us/step - loss: 0.1811 - acc: 0.9492\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.1773 - acc: 0.95040s - loss: 0.17\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 15s 253us/step - loss: 0.1733 - acc: 0.9521\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.1695 - acc: 0.9521\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 15s 244us/step - loss: 0.1660 - acc: 0.9536\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 15s 257us/step - loss: 0.1626 - acc: 0.9546\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.1598 - acc: 0.9557\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.1561 - acc: 0.9566\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 16s 261us/step - loss: 0.1531 - acc: 0.9573\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 20s 326us/step - loss: 0.1504 - acc: 0.9585\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 18s 304us/step - loss: 0.1475 - acc: 0.9597\n",
      "Epoch 40/50\n",
      " 9700/60000 [===>..........................] - ETA: 13s - loss: 0.1409 - acc: 0.9604"
     ]
    }
   ],
   "source": [
    "# Prompt user to load or re-run the training.\n",
    "option = input(\"Please choose an option and press enter: \\n\"\n",
    "               \"Load model = y/ train model = n \\n\")\n",
    "if option == 'y':\n",
    "    # Adapted from: https://stackoverflow.com/questions/82831/how-do-i-check-whether-a-file-exists-without-exceptions\n",
    "    # Check if the model file exists\n",
    "    my_file = Path(\"data/my_model.h5\")\n",
    "    if my_file.is_file():\n",
    "        load_model()\n",
    "    else:\n",
    "        print(\"No file exists running training.....\")\n",
    "        train_model()\n",
    "elif option == 'n':\n",
    "    train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the network with test images\n",
    "\n",
    "The test images and labels are unzipped and stored in memory using the same methods as the training images and labels.<br/>\n",
    "\n",
    "A single image can then be sent to the network to see if it is identifying the number correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the gzipped test images and labels\n",
    "# Adapted from : https://docs.python.org/2/library/gzip.html\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "\n",
    "# Store each image and label into memory\n",
    "# Adapted from: https://raw.githubusercontent.com/ianmcloughlin/jupyter-teaching-notebooks/master/mnist.ipynb\n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the performance results\n",
    "\n",
    "The below result shows that 9622 images have been identified correctly this matches the final accuracy of the training output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the total number of correct images identified out of 10000 test images\n",
    "performance = (encoder.inverse_transform(model.predict(test_img)) == test_lbl).sum()\n",
    "print(\"The correct number of predictions: \", performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing an image to the network\n",
    "In the below example the 128th image in the dataset is passed to the network for identification.<br/>\n",
    "The result is then printed out for us to examine as an array.<br/>\n",
    "The index with the highest value within this array represents the number that has been picked by the network.<br/>\n",
    "In this case the number identified by the network is eight as the ninth position in the array is the highest value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = model.predict(test_img[128:129])\n",
    "# Print the\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing out the results.\n",
    "\n",
    "We can get the array index with the highest value by using the argmax function.<br/>\n",
    "This will return the index of the array with the highest value in this case it is eight.<br/>\n",
    "Additionally the label for the image can be accessed using the same index as used for the test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the maximum value from the machine prediction\n",
    "pred_result = test.argmax(axis=1)\n",
    "\n",
    "print(\"The machine prediction is : =>> \",  pred_result)\n",
    "print(\"The actual number is : =>> \", test_lbl[128:129])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing some more images \n",
    "\n",
    "Below we will test twenty more images selected at random to see if the network is performing as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get 20 random images form the test set and pass them to the trained model.\n",
    "# Random int adapted from https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9\n",
    "from random import randint\n",
    "# Select 20 images\n",
    "for i in range(20):\n",
    "    # The test number\n",
    "    print(\"Test Number : \", i+1,\"\\n\")\n",
    "    # Get a random value between 1 and 10000\n",
    "    x = randint(0, 9999)\n",
    "    # PRint the random value\n",
    "    print(\"The random index: \", x, \"\\n\")\n",
    "    print(\"The result array: \")\n",
    "    # Predicting the number passed in\n",
    "    test = model.predict(test_img[x:x+1])\n",
    "    # Print the result array\n",
    "    print(test, \"\\n\")\n",
    "    # Get the maximum value from the machine predictions\n",
    "    pred_result = test.argmax(axis=1)\n",
    "\n",
    "    print(\"The machine prediction is : =>> \",  pred_result)\n",
    "    print(\"The actual number is : =>> \", test_lbl[x:x+1])\n",
    "    print(\"##############################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "The above output shows that the network has all of the numbers correct on this run.<br/>\n",
    "However as it has a 96.5% accuracy it will get 3.5 predictions wrong out of every 100 test images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading you own images for testing\n",
    "The code below will allow the user to upload their own images of any size.<br/>\n",
    "When prompted if the user chooses 'y' tkinter's file dialog will open where the user can choose an image file to test with the network.<br/>\n",
    "The image is then coloured to greyscale and resized to 28 x 28 pixels.<br/>\n",
    "Finally the image is converted to an array and flattened to 784 bytes. <br/>\n",
    "This will convert the image to the same format as the mnist data and can now be used to pass to the network for identification.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uploading your own images for testing\n",
    "# input file adapted from https://stackoverflow.com/questions/9319317/quick-and-easy-file-dialog-in-python\n",
    "def file_upload():\n",
    "    # tkinter for uploading file\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()\n",
    "    \n",
    "    # -topmost, True to ensure the upload screen appears on top of the current window.\n",
    "    #Adapted from: https://stackoverflow.com/questions/31778176/how-do-i-get-tkinter-askopenfilename-to-open-on-top-of-other-windows\n",
    "    root.attributes(\"-topmost\", True)\n",
    "    \n",
    "    # get the file path from the chosen file in the dialog box\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    \n",
    "    # Adapted from https://towardsdatascience.com/basics-of-image-classification-with-keras-43779a299c8b\n",
    "    # resize the image that has been uploaded\n",
    "    img = image.load_img(path=file_path,color_mode = \"grayscale\",target_size=(28,28,1))\n",
    "    \n",
    "    # flatten the image\n",
    "    imgage1 = np.array(list(image.img_to_array(img))).reshape(1, 784).astype(np.uint8) / 255.0\n",
    "\n",
    "    # Test the network with new image\n",
    "    test1 = model.predict(imgage1)\n",
    "\n",
    "    # Print out the result of the prediction\n",
    "    print(\"The number predicted is : \", test1.argmax(axis=1))\n",
    "\n",
    "# Boolean for while loop\n",
    "keep_running = True\n",
    "\n",
    "while keep_running:\n",
    "    upload_img = input(\"upload image? \\n\"\n",
    "                   \" press 'y' + enter (to upload)\\n\"\n",
    "                   \"press 'n'  + enter (to exit)\")\n",
    "\n",
    "    if upload_img == 'y':\n",
    "        # Call the file_upload function.\n",
    "        file_upload()\n",
    "    elif upload_img == 'n':\n",
    "        # exit the loop.\n",
    "        keep_running = False\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
