{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital recognition with the mnist dataset\n",
    "\n",
    "This notebook will investigate the classification and identification of hand written digits using a neural network.<br/>\n",
    "The mnist dataset will be first used to train the network and then test the networks performance in recognising a digit.<br/>\n",
    "Once training has been completed a single image from the dataset will be passed to the network and the result will be displayed to the screen along with the actual digit expected.<br/>\n",
    "![Mnist Image](https://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png)\n",
    "<cite>Image source https://corochann.com/wp-content/uploads/2017/02/mnist_plot-800x600.png</cite>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages needed for the program to run\n",
    "\n",
    "The following packages will need to be imported for creating the network and importing the images to memory:\n",
    "* The keras package used for creating the network\n",
    "* The gzip package used for unzipping the dataset images and labels\n",
    "* The numpy package used for altering the dataset into numpy arrays\n",
    "* The sklearn pre-processing package used for classification and binary encoding each digit\n",
    "* The random package used to generate a random value for the test images\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kevin\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the packages \n",
    "import keras as kr\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as pre\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the neural network\n",
    "To begin we need to initialise the network using the sequential model.<br/>\n",
    "This allows us to add layers as we need them. <br/>\n",
    "These layers can be tweaked to increase performance.<br/>\n",
    "We will investigate this later in the notebook.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the neural network\n",
    "model = kr.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the layers to the network\n",
    "To add layers to the network the layers method from keras will be used.<br/>\n",
    "There will be a dense connection between neurons meaning that every neuron from the input is connected to every neuron in the middle layer and every neuron frim the middle layer is connected to every neuron on the output layer.\n",
    "\n",
    "![Neural Network](https://cdn-images-1.medium.com/max/800/1*jYhgQ4I_oFdxgDD-AOgV1w.png)\n",
    "<cite>Image source https://cdn-images-1.medium.com/max/800/1*jYhgQ4I_oFdxgDD-AOgV1w.pngS</cite>\n",
    "\n",
    "* In the below code segment the units attribute represents the amount of neurons that will be in the middle layer in this case we have 1000 neurons.<br/>\n",
    "* The activation attribute sets the activation function in this case we are using  [relu activation](https://keras.io/activations/) the relu activation has a steeper gradient than softmax and as a result speeds up the training process without the loss of performance. \n",
    "\n",
    "* The final attribute is used to set the amount of input neurons the network has. In the below example the number is set to 784 as this is equal to the number of bytes each image has within the mnist dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a hidden(middle layer) with 1000 neurons and an input layer with 784.\n",
    "# There are 784 input neurons as this value is equal to the total amount of bytes each image has.\n",
    "model.add(kr.layers.Dense(units=1000, activation='relu', input_dim=784))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output layer\n",
    "The output layer has ten neurons that will map to the amount of training labels that are within the dataset. The predicted results are sent from the middle layer to the output layer and compared to the actual number that has been sent in as image data.<br/>\n",
    "The closer to the value one the result is the more accurate the algorithm is performing.<br/>\n",
    "While this process is repeating the loss point of gradient decent converges towards the base of the slope. <br/>\n",
    "The process ends when all of the epochs have completed which will be explained later in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ten neurons to the output layer\n",
    "model.add(kr.layers.Dense(units=10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "The compile method is used to build the model based on each layer created along with their connections specified in the above cell.</br>\n",
    "* The first argument [categorical_crossentropy](https://keras.io/losses/) creates a vector to hold the values of each digit as a binary representation, this will be set with the pre.LabelBinarizer() to be discussed further in this notebook.\n",
    "* The second optimizer argument is set to [stochastic gradient descent optimizer](https://keras.io/optimizers/) This sets the learning rate, and the decay of this learning rate over time.\n",
    "* The final argument [metrics](https://keras.io/metrics/) is used to output the performance to the neural network after each run of data has been sent from the central layer to the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the graph.\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening the files in .gz format\n",
    "\n",
    "As discussed in my previous [mnist notebook](https://github.com/kevgleeson78/Emerge-tech-assign/blob/master/Mnist%20Dataset.ipynb) the gzipped files are opened and read using the gzip package.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the gzipped files and read as bytes.\n",
    "with gzip.open('data/train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    train_img = f.read()\n",
    "\n",
    "with gzip.open('data/train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    train_lbl = f.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in the data into memory\n",
    "\n",
    "Each of the 60000 images and labels are then stored into their respective variables.<br/>\n",
    "We dived by 255 to convert the grey scale value to a value between one and zero.<br/>\n",
    "These values are then used by the neural network in conjunction with the softmax function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in all images and labels into memory\n",
    "train_img = ~np.array(list(train_img[16:])).reshape(60000, 28, 28).astype(np.uint8) / 255.0\n",
    "train_lbl =  np.array(list(train_lbl[8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening the data into a single array\n",
    "The data is converted from a three dimensional array to a one dimensional array where all of the image bytes (28 *28) 784 are sequentially stored one after another.<br/>\n",
    "This technique is used so each byte representing the image can have a one to one mapping to the neural networks input layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.98823529, 0.92941176, 0.92941176,\n",
       "        0.92941176, 0.50588235, 0.46666667, 0.31372549, 0.89803922,\n",
       "        0.34901961, 0.        , 0.03137255, 0.50196078, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.88235294, 0.85882353, 0.63137255, 0.39607843,\n",
       "        0.33333333, 0.00784314, 0.00784314, 0.00784314, 0.00784314,\n",
       "        0.00784314, 0.11764706, 0.3254902 , 0.00784314, 0.05098039,\n",
       "        0.23529412, 0.74901961, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.80784314, 0.06666667,\n",
       "        0.00784314, 0.00784314, 0.00784314, 0.00784314, 0.00784314,\n",
       "        0.00784314, 0.00784314, 0.00784314, 0.01568627, 0.63529412,\n",
       "        0.67843137, 0.67843137, 0.78039216, 0.84705882, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.92941176, 0.14117647, 0.00784314, 0.00784314,\n",
       "        0.00784314, 0.00784314, 0.00784314, 0.22352941, 0.28627451,\n",
       "        0.03137255, 0.05490196, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.68627451, 0.38823529, 0.58039216, 0.00784314, 0.00784314,\n",
       "        0.19607843, 0.95686275, 1.        , 0.83137255, 0.39607843,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.94509804,\n",
       "        0.99607843, 0.39607843, 0.00784314, 0.64705882, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.45490196,\n",
       "        0.00784314, 0.25490196, 0.99215686, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.95686275, 0.25490196, 0.00784314,\n",
       "        0.7254902 , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.8627451 , 0.05490196, 0.11764706, 0.37254902,\n",
       "        0.57647059, 0.99607843, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.68235294, 0.05882353, 0.00784314, 0.00784314, 0.53333333,\n",
       "        0.90196078, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.82352941,\n",
       "        0.27058824, 0.00784314, 0.00784314, 0.41176471, 0.89411765,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.9372549 , 0.63529412,\n",
       "        0.01176471, 0.00784314, 0.26666667, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.02352941, 0.00784314,\n",
       "        0.02352941, 0.74901961, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.81960784, 0.49019608,\n",
       "        0.28235294, 0.00784314, 0.00784314, 0.18823529, 0.99215686,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 0.84705882,\n",
       "        0.41960784, 0.10196078, 0.00784314, 0.00784314, 0.00784314,\n",
       "        0.01960784, 0.28627451, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        0.90588235, 0.55294118, 0.13333333, 0.00784314, 0.00784314,\n",
       "        0.00784314, 0.00784314, 0.21176471, 0.69411765, 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.90980392, 0.74117647, 0.16470588, 0.00784314,\n",
       "        0.00784314, 0.00784314, 0.00784314, 0.22352941, 0.68235294,\n",
       "        0.99215686, 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 0.92941176, 0.32941176, 0.14117647,\n",
       "        0.00784314, 0.00784314, 0.00784314, 0.00784314, 0.23529412,\n",
       "        0.68627451, 0.96470588, 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 0.78431373, 0.3254902 ,\n",
       "        0.11372549, 0.00784314, 0.00784314, 0.00784314, 0.00784314,\n",
       "        0.04313725, 0.47843137, 0.95686275, 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 0.46666667, 0.00784314, 0.00784314, 0.00784314,\n",
       "        0.16862745, 0.47058824, 0.48235294, 0.9372549 , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "        1.        , 1.        , 1.        , 1.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the array so the inputs can be mapped to the input neurons\n",
    "inputs = train_img.reshape(60000, 784)\n",
    "inputs[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding the data\n",
    "The label data is encoded into a matrix of 10 x 10 this will represent the digits in binary format.\n",
    "Firstly we to setup the matrix using the labelBinerizer function.<br/>\n",
    "The fit function passes the training labels as an argument. AS the set of labels are from zero - nine the (encoder.fit) function generates a matrix based on these values. In this case it will be a 10 x 10 matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode the labels into binary format\n",
    "encoder = pre.LabelBinarizer()\n",
    "# get the size of the array needed for each category\n",
    "encoder.fit(train_lbl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming the labels\n",
    "The labels are then transformed to a binary value based on the decimal value of the label.</br>\n",
    "With each number being transformed to the following:\n",
    "* (0) 1000000000\n",
    "* (1) 0100000000\n",
    "* (3) 0010000000 \n",
    "\n",
    "And so on until we reach the number nine which is 0000000001.<br/>\n",
    "\n",
    "\n",
    "In the below example the number five has the representation of '0 0 0 0 0 1 0 0 0 0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 [0 0 0 0 0 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# encode each label to be used as binary outputs\n",
    "outputs = encoder.transform(train_lbl)\n",
    "# print out the integer value and the new representation of the number\n",
    "print(train_lbl[0], outputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full example\n",
    "Below is a full view of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [[1 0 0 0 0 0 0 0 0 0]]\n",
      "1 [[0 1 0 0 0 0 0 0 0 0]]\n",
      "2 [[0 0 1 0 0 0 0 0 0 0]]\n",
      "3 [[0 0 0 1 0 0 0 0 0 0]]\n",
      "4 [[0 0 0 0 1 0 0 0 0 0]]\n",
      "5 [[0 0 0 0 0 1 0 0 0 0]]\n",
      "6 [[0 0 0 0 0 0 1 0 0 0]]\n",
      "7 [[0 0 0 0 0 0 0 1 0 0]]\n",
      "8 [[0 0 0 0 0 0 0 0 1 0]]\n",
      "9 [[0 0 0 0 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "# print out each array\n",
    "for i in range(10):\n",
    "    print(i, encoder.transform([i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "We are now ready to begin training the network to recognise the images.</br>\n",
    "The training set of 60000 images are used and passed to the networks first layer of 784 neurons.<br/>\n",
    "Model parameters:\n",
    "1. The encoded training images are sent as input\n",
    "2. The encoded training labels are attached as the expected output\n",
    "3. Epochs is the amount of times the 60000 images will be processed \n",
    "4. The batch size sets the amount of images that will be sent to the network as one unit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 16s 260us/step - loss: 0.8802 - acc: 0.7845\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 15s 247us/step - loss: 0.4629 - acc: 0.8749\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 15s 243us/step - loss: 0.3956 - acc: 0.8895\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 15s 251us/step - loss: 0.3635 - acc: 0.8973\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 15s 252us/step - loss: 0.3435 - acc: 0.9021\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 15s 248us/step - loss: 0.3291 - acc: 0.9059\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 15s 248us/step - loss: 0.3172 - acc: 0.9085\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 15s 245us/step - loss: 0.3061 - acc: 0.91221s - loss: 0.30\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.2974 - acc: 0.9149\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 15s 254us/step - loss: 0.2899 - acc: 0.9168\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 15s 249us/step - loss: 0.2825 - acc: 0.9191\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 15s 246us/step - loss: 0.2751 - acc: 0.9219\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 15s 250us/step - loss: 0.2693 - acc: 0.9237\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 15s 255us/step - loss: 0.2622 - acc: 0.9259\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.2565 - acc: 0.9275\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.2501 - acc: 0.9296\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 18s 299us/step - loss: 0.2443 - acc: 0.9313\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 17s 289us/step - loss: 0.2384 - acc: 0.9319\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 0.2325 - acc: 0.9342\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 0.2273 - acc: 0.9365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cda7b6c080>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the training\n",
    "# Set the model up by adding the input and output layers to the network\n",
    "#The epochs value is the amount of test runs are needed\n",
    "# The batch_size value is the amount of images sent at one time to the network\n",
    "model.fit(inputs, outputs, epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results of the training\n",
    "\n",
    "The above result shows that the network is getting approx 93.6% of the images correct for the training set after 20 runs of the test.<br/>\n",
    "As we can see with each epoch the performance is slightly increasing and the loss is converging towards zero (The optimal value).\n",
    "\n",
    "Below we will try for a further 10 epochs to see if the performance increases. Please note that the previous cell needs to have run first so the learning data can be carried over rerun all cells to be certain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 0.2218 - acc: 0.9387\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 262us/step - loss: 0.2166 - acc: 0.9390\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.2118 - acc: 0.9415\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 0.2069 - acc: 0.94220s - loss: 0.20\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.2019 - acc: 0.9441\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.1980 - acc: 0.9446\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.1932 - acc: 0.9462\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 0.1894 - acc: 0.9473\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.1852 - acc: 0.9486\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.1813 - acc: 0.9496\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cdaaddb080>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the training\n",
    "# Set the model up by adding the input and output layers to the network\n",
    "#The epochs value is the amount of test runs are needed\n",
    "# The batch_size value is the amount of images sent at one time to the network\n",
    "model.fit(inputs, outputs, epochs=10, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "As we can see there has been an increase of almost 1.5% in performance. We will now try a further 20 epochs to see if it will further increase the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 16s 272us/step - loss: 0.1774 - acc: 0.9508\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 16s 269us/step - loss: 0.1738 - acc: 0.9516\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 16s 268us/step - loss: 0.1703 - acc: 0.9523\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.1669 - acc: 0.9532\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 16s 271us/step - loss: 0.1634 - acc: 0.9541\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 16s 266us/step - loss: 0.1603 - acc: 0.9553\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - ETA: 0s - loss: 0.1572 - acc: 0.956 - 16s 268us/step - loss: 0.1571 - acc: 0.9562\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 16s 270us/step - loss: 0.1539 - acc: 0.9579\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 0.1511 - acc: 0.9580\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 16s 266us/step - loss: 0.1485 - acc: 0.9588\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 16s 264us/step - loss: 0.1458 - acc: 0.9599\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 16s 265us/step - loss: 0.1432 - acc: 0.9604\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.1404 - acc: 0.9612\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.1378 - acc: 0.9619\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.1354 - acc: 0.9632\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 17s 282us/step - loss: 0.1331 - acc: 0.9637\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 17s 283us/step - loss: 0.1309 - acc: 0.9637\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 17s 279us/step - loss: 0.1287 - acc: 0.9647\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 17s 281us/step - loss: 0.1264 - acc: 0.9657\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 17s 280us/step - loss: 0.1241 - acc: 0.9662\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cdaaddb048>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start the training\n",
    "# Set the model up by adding the input and output layers to the network\n",
    "#The epochs value is the amount of test runs are needed\n",
    "# The batch_size value is the amount of images sent at one time to the network\n",
    "model.fit(inputs, outputs, epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "By running a further 20 epochs we have got a result of apporx 96.5% a further increase of 1.5% accuracy.<br/>\n",
    "This indicates that the more epochs are run with these parameters set we could get to an accuracy of 98% if enough tests were run.<br/>\n",
    "For the purpose of testing the network with the test images this level of accuracy will suffice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the network with test images\n",
    "\n",
    "The test images and labels are unzipped and stored in memory using the same methods as the training images and labels.<br/>\n",
    "\n",
    "A single image can then be sent to the network to see if it is identifying the number correctly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the gzipped test images and labels\n",
    "with gzip.open('data/t10k-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    test_img = f.read()\n",
    "\n",
    "with gzip.open('data/t10k-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    test_lbl = f.read()\n",
    "\n",
    "# Store each image and label into memory\n",
    "test_img = ~np.array(list(test_img[16:])).reshape(10000, 784).astype(np.uint8) / 255.0\n",
    "test_lbl =  np.array(list(test_lbl[ 8:])).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing an image to the network\n",
    "In the below example the 128th image in the dataset is passed to the network for identification.<br/>\n",
    "The result is then printed out for us to examine as an array.<br/>\n",
    "The index with the highest value within this array represents the number that has been picked by the network.<br/>\n",
    "In this case the number identified by the network is eight as the eighth position in the array is the highest value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.2227084e-07 1.5695909e-07 7.2410468e-05 3.5107702e-03 1.1336579e-06\n",
      "  2.2143700e-04 5.5963032e-08 1.7481779e-06 9.9605149e-01 1.4050568e-04]]\n"
     ]
    }
   ],
   "source": [
    "test = model.predict(test_img[128:129])\n",
    "# Print the\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing out the results.\n",
    "\n",
    "We can get the array index with the highest value by using the argmax function.<br/>\n",
    "This will return the index of the array with the highest value in this case it is eight.<br/>\n",
    "Additionally the label for the image can be accessed using the same index as used for the test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The machine prediction is : =>>  [8]\n",
      "The actual number is : =>>  [8]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the maximum value from the machine predictions\n",
    "pred_result = test.argmax(axis=1)\n",
    "\n",
    "print(\"The machine prediction is : =>> \",  pred_result)\n",
    "print(\"The actual number is : =>> \", test_lbl[128:129])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing some more images \n",
    "\n",
    "Below we will test twenty more images selected at random to see if the network is performing as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Number :  1 \n",
      "\n",
      "The random index:  9322 \n",
      "\n",
      "The result array: \n",
      "[[3.2219526e-05 1.0110136e-04 6.4283429e-04 6.1476715e-03 9.3721883e-06\n",
      "  1.8840386e-03 8.4162994e-06 2.5210184e-06 9.8971128e-01 1.4604974e-03]] \n",
      "\n",
      "The machine prediction is : =>>  [8]\n",
      "The actual number is : =>>  [8]\n",
      "##############################################\n",
      "Test Number :  2 \n",
      "\n",
      "The random index:  563 \n",
      "\n",
      "The result array: \n",
      "[[6.5419088e-05 2.2438895e-04 2.9543354e-03 2.8649850e-03 8.9443137e-04\n",
      "  3.3773310e-03 3.8906106e-05 8.3041094e-05 9.8531783e-01 4.1793240e-03]] \n",
      "\n",
      "The machine prediction is : =>>  [8]\n",
      "The actual number is : =>>  [8]\n",
      "##############################################\n",
      "Test Number :  3 \n",
      "\n",
      "The random index:  1513 \n",
      "\n",
      "The result array: \n",
      "[[2.09873411e-04 7.61297345e-03 4.67214966e-04 9.79015112e-01\n",
      "  2.10917096e-05 1.01832915e-02 2.20747861e-05 6.45907829e-04\n",
      "  1.27547549e-03 5.46892872e-04]] \n",
      "\n",
      "The machine prediction is : =>>  [3]\n",
      "The actual number is : =>>  [3]\n",
      "##############################################\n",
      "Test Number :  4 \n",
      "\n",
      "The random index:  7576 \n",
      "\n",
      "The result array: \n",
      "[[2.4246214e-05 4.8137359e-08 3.8037071e-04 8.6887178e-07 2.0046449e-05\n",
      "  8.4132344e-06 9.9953818e-01 1.1084619e-08 2.7607673e-05 2.9425570e-07]] \n",
      "\n",
      "The machine prediction is : =>>  [6]\n",
      "The actual number is : =>>  [6]\n",
      "##############################################\n",
      "Test Number :  5 \n",
      "\n",
      "The random index:  7856 \n",
      "\n",
      "The result array: \n",
      "[[1.4502105e-03 6.4734119e-01 5.7453424e-02 1.3913413e-02 2.5069446e-04\n",
      "  3.1494402e-04 9.0728054e-04 1.0360645e-03 2.7683085e-01 5.0186616e-04]] \n",
      "\n",
      "The machine prediction is : =>>  [1]\n",
      "The actual number is : =>>  [1]\n",
      "##############################################\n",
      "Test Number :  6 \n",
      "\n",
      "The random index:  2667 \n",
      "\n",
      "The result array: \n",
      "[[3.7462542e-05 8.6202432e-05 3.0805374e-04 6.5126189e-04 9.3020215e-05\n",
      "  2.2305315e-03 1.5173301e-04 5.6015313e-07 9.9588120e-01 5.6001195e-04]] \n",
      "\n",
      "The machine prediction is : =>>  [8]\n",
      "The actual number is : =>>  [8]\n",
      "##############################################\n",
      "Test Number :  7 \n",
      "\n",
      "The random index:  1654 \n",
      "\n",
      "The result array: \n",
      "[[6.87118540e-09 2.61161220e-03 9.72503245e-01 1.35523230e-02\n",
      "  4.97481597e-05 1.22315407e-06 1.56037742e-04 1.09878294e-02\n",
      "  1.09708504e-04 2.82307738e-05]] \n",
      "\n",
      "The machine prediction is : =>>  [2]\n",
      "The actual number is : =>>  [2]\n",
      "##############################################\n",
      "Test Number :  8 \n",
      "\n",
      "The random index:  5227 \n",
      "\n",
      "The result array: \n",
      "[[3.1874049e-06 9.8863900e-01 1.3494090e-03 8.6316431e-05 2.8602713e-06\n",
      "  1.2507928e-04 4.0382458e-04 5.9637423e-05 9.3127256e-03 1.7975748e-05]] \n",
      "\n",
      "The machine prediction is : =>>  [1]\n",
      "The actual number is : =>>  [1]\n",
      "##############################################\n",
      "Test Number :  9 \n",
      "\n",
      "The random index:  6484 \n",
      "\n",
      "The result array: \n",
      "[[5.5916394e-06 9.9093026e-01 6.2590502e-03 1.5897118e-04 6.5111503e-06\n",
      "  1.2176241e-04 4.1789023e-04 2.3769999e-04 1.8503509e-03 1.1896328e-05]] \n",
      "\n",
      "The machine prediction is : =>>  [1]\n",
      "The actual number is : =>>  [1]\n",
      "##############################################\n",
      "Test Number :  10 \n",
      "\n",
      "The random index:  7233 \n",
      "\n",
      "The result array: \n",
      "[[5.9107598e-03 7.5675480e-02 2.2291916e-03 4.9336657e-01 2.5949417e-05\n",
      "  2.6750442e-01 1.9623258e-04 6.6819556e-02 8.3740078e-02 4.5318524e-03]] \n",
      "\n",
      "The machine prediction is : =>>  [3]\n",
      "The actual number is : =>>  [3]\n",
      "##############################################\n",
      "Test Number :  11 \n",
      "\n",
      "The random index:  4730 \n",
      "\n",
      "The result array: \n",
      "[[1.66522350e-05 3.81903874e-06 1.25559105e-04 2.66392063e-03\n",
      "  7.68464133e-07 6.14808305e-05 2.06664783e-08 9.97020185e-01\n",
      "  3.18979778e-06 1.04352664e-04]] \n",
      "\n",
      "The machine prediction is : =>>  [7]\n",
      "The actual number is : =>>  [7]\n",
      "##############################################\n",
      "Test Number :  12 \n",
      "\n",
      "The random index:  7562 \n",
      "\n",
      "The result array: \n",
      "[[1.4807921e-06 5.0742942e-06 6.5327913e-07 3.5415872e-04 3.4836440e-03\n",
      "  1.1860467e-04 1.1484118e-06 1.2232205e-03 2.1130325e-04 9.9460077e-01]] \n",
      "\n",
      "The machine prediction is : =>>  [9]\n",
      "The actual number is : =>>  [9]\n",
      "##############################################\n",
      "Test Number :  13 \n",
      "\n",
      "The random index:  5733 \n",
      "\n",
      "The result array: \n",
      "[[2.5601005e-07 1.1420688e-05 9.9974436e-01 3.6413341e-05 1.8574651e-08\n",
      "  8.2276722e-07 3.5447154e-06 2.5741553e-09 2.0307675e-04 4.5596131e-09]] \n",
      "\n",
      "The machine prediction is : =>>  [2]\n",
      "The actual number is : =>>  [2]\n",
      "##############################################\n",
      "Test Number :  14 \n",
      "\n",
      "The random index:  4190 \n",
      "\n",
      "The result array: \n",
      "[[4.6097600e-07 9.9393988e-01 3.2631549e-04 2.7596962e-03 3.1095649e-05\n",
      "  3.6997377e-04 3.2761169e-04 6.4438418e-04 1.0596414e-03 5.4107897e-04]] \n",
      "\n",
      "The machine prediction is : =>>  [1]\n",
      "The actual number is : =>>  [1]\n",
      "##############################################\n",
      "Test Number :  15 \n",
      "\n",
      "The random index:  6254 \n",
      "\n",
      "The result array: \n",
      "[[1.6834049e-06 9.9457967e-01 1.0267750e-03 5.7885068e-04 2.1806713e-05\n",
      "  9.3528113e-05 5.6746067e-05 2.0323340e-03 1.5434016e-03 6.5170345e-05]] \n",
      "\n",
      "The machine prediction is : =>>  [1]\n",
      "The actual number is : =>>  [1]\n",
      "##############################################\n",
      "Test Number :  16 \n",
      "\n",
      "The random index:  8046 \n",
      "\n",
      "The result array: \n",
      "[[5.1573741e-05 4.2011607e-07 7.1013586e-05 3.9421700e-04 6.6591269e-07\n",
      "  1.3089934e-05 1.9640389e-07 2.6305104e-04 9.9513823e-01 4.0675388e-03]] \n",
      "\n",
      "The machine prediction is : =>>  [8]\n",
      "The actual number is : =>>  [8]\n",
      "##############################################\n",
      "Test Number :  17 \n",
      "\n",
      "The random index:  5321 \n",
      "\n",
      "The result array: \n",
      "[[9.9998200e-01 2.8667858e-11 7.0484271e-06 4.1672325e-07 5.1252163e-09\n",
      "  2.9515309e-06 1.2492580e-07 2.4516748e-06 2.2913619e-06 2.7939229e-06]] \n",
      "\n",
      "The machine prediction is : =>>  [0]\n",
      "The actual number is : =>>  [0]\n",
      "##############################################\n",
      "Test Number :  18 \n",
      "\n",
      "The random index:  1065 \n",
      "\n",
      "The result array: \n",
      "[[2.7083169e-09 8.1462618e-05 9.9965847e-01 1.8106292e-04 3.4672258e-11\n",
      "  3.8173674e-08 4.5584670e-08 6.5912005e-09 7.9037716e-05 7.5091572e-10]] \n",
      "\n",
      "The machine prediction is : =>>  [2]\n",
      "The actual number is : =>>  [2]\n",
      "##############################################\n",
      "Test Number :  19 \n",
      "\n",
      "The random index:  138 \n",
      "\n",
      "The result array: \n",
      "[[2.3672619e-05 1.9506244e-07 7.7223922e-05 5.4964164e-07 9.5860858e-05\n",
      "  1.0610208e-05 9.9977142e-01 5.5936343e-06 1.3861340e-05 1.0783467e-06]] \n",
      "\n",
      "The machine prediction is : =>>  [6]\n",
      "The actual number is : =>>  [6]\n",
      "##############################################\n",
      "Test Number :  20 \n",
      "\n",
      "The random index:  5949 \n",
      "\n",
      "The result array: \n",
      "[[2.1063319e-07 1.3515299e-04 3.7391586e-05 7.5654779e-03 1.9726422e-04\n",
      "  1.7764815e-04 2.8930179e-07 9.8645246e-01 3.5300016e-04 5.0811884e-03]] \n",
      "\n",
      "The machine prediction is : =>>  [7]\n",
      "The actual number is : =>>  [7]\n",
      "##############################################\n"
     ]
    }
   ],
   "source": [
    "# Random int adapted from https://stackoverflow.com/questions/3996904/generate-random-integers-between-0-and-9\n",
    "from random import randint\n",
    "for i in range(20):\n",
    "    print(\"Test Number : \", i+1,\"\\n\")\n",
    "    x = randint(0, 9999)\n",
    "    print(\"The random index: \", x, \"\\n\")\n",
    "    print(\"The result array: \")\n",
    "    test = model.predict(test_img[x:x+1])\n",
    "    # Print the\n",
    "    print(test, \"\\n\")\n",
    "    # Get the maximum value from the machine predictions\n",
    "    pred_result = test.argmax(axis=1)\n",
    "\n",
    "    print(\"The machine prediction is : =>> \",  pred_result)\n",
    "    print(\"The actual number is : =>> \", test_lbl[x:x+1])\n",
    "    print(\"##############################################\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "The above output shows that the network has all of the numbers correct on this run.<br/>\n",
    "However as it has a 96% accuracy it will get 3.5 predictions wrong out of every 100 test images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
